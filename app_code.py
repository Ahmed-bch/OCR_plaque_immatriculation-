import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import time
import atexit
from datetime import datetime
import pandas as pd
from ultralytics import YOLO
from fast_plate_ocr import LicensePlateRecognizer
import logging
from pathlib import Path
import json
from difflib import SequenceMatcher

# Tentative d'importation de streamlit_webrtc avec gestion d'erreur
try:
    from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, VideoFrame
    WEBRTC_AVAILABLE = True
except ImportError:
    WEBRTC_AVAILABLE = False
    st.warning("‚ö†Ô∏è streamlit-webrtc n'est pas disponible. La d√©tection en temps r√©el sera d√©sactiv√©e.")

# ===============================
# Constantes pour les plaques alg√©riennes
# ===============================

WILAYAS = {
    "01": "Adrar", "02": "Chlef", "03": "Laghouat", "04": "Oum El Bouaghi",
    "05": "Batna", "06": "B√©ja√Øa", "07": "Biskra", "08": "B√©char",
    "09": "Blida", "10": "Bouira", "11": "Tamanrasset", "12": "T√©bessa",
    "13": "Tlemcen", "14": "Tiaret", "15": "Tizi Ouzou", "16": "Alger",
    "17": "Djelfa", "18": "Jijel", "19": "S√©tif", "20": "Sa√Øda",
    "21": "Skikda", "22": "Sidi Bel Abb√®s", "23": "Annaba", "24": "Guelma",
    "25": "Constantine", "26": "M√©d√©a", "27": "Mostaganem", "28": "M\u2019Sila",
    "29": "Mascara", "30": "Ouargla", "31": "Oran", "32": "El Bayadh",
    "33": "Illizi", "34": "Bordj Bou Arr√©ridj", "35": "Boumerd√®s", "36": "El Tarf",
    "37": "Tindouf", "38": "Tissemsilt", "39": "El Oued", "40": "Khenchela",
    "41": "Souk Ahras", "42": "Tipaza", "43": "Mila", "44": "A√Øn Defla",
    "45": "Naama", "46": "A√Øn T√©mouchent", "47": "Gharda√Øa", "48": "Relizane",
    "49": "Timimoun", "50": "Bordj Badji Mokhtar", "51": "Ouled Djellal",
    "52": "B√©ni Abb√®s", "53": "In Salah", "54": "In Guezzam", "55": "Touggourt",
    "56": "Djanet", "57": "El M\u2019Ghair", "58": "El Menia"
}

VEHICLE_CATEGORIES = {
    "1": "v√©hicules de tourisme (v√©hicules particuliers)",
    "2": "camions",
    "3": "camionnettes",
    "4": "autocars et autobus",
    "5": "tracteurs routiers",
    "6": "autres tracteurs",
    "7": "v√©hicules sp√©ciaux",
    "8": "remorques et semi-remorques",
    "9": "motocyclettes (deux (2) roues ou plus)"
}

# ===============================
# Fonctions utilitaires pour les plaques
# ===============================

def clean_plate_text(plate_text: str) -> str:
    """Remplace les tirets par des espaces dans le texte de la plaque."""
    return plate_text.replace("-", " ")

def parse_plate_info(plate_text: str) -> dict:
    """Extrait les informations (num√©ro de s√©rie, cat√©gorie, ann√©e, wilaya) d'une plaque alg√©rienne.
    La plaque doit √™tre au format continu (sans tirets) et de 10 ou 11 caract√®res.
    Ex: '1234511816' (5 chiffres pour le num√©ro de s√©rie) ou '12345621825' (6 chiffres).
    """
    info = {
        "serial_number": None,
        "category": None,
        "year": None,
        "wilaya": None,
        "is_valid": False,
        "error": ""
    }

    # Supprimer les tirets si l'OCR les a inclus par erreur
    plate_text = plate_text.replace("-", "").strip()

    if not plate_text.isdigit():
        info["error"] = "La plaque ne contient pas que des chiffres."
        return info

    if len(plate_text) == 10:  # Format: SSSSSCYW (5 chiffres s√©rie, 1 cat√©gorie, 2 ann√©e, 2 wilaya)
        serial_number_str = plate_text[0:5]
        category_year_str = plate_text[5:8]
        wilaya_str = plate_text[8:10]
    elif len(plate_text) == 11: # Format: SSSSSSCCYW (6 chiffres s√©rie, 1 cat√©gorie, 2 ann√©e, 2 wilaya)
        serial_number_str = plate_text[0:6]
        category_year_str = plate_text[6:9]
        wilaya_str = plate_text[9:11]
    else:
        info["error"] = f"Longueur de plaque invalide: {len(plate_text)} caract√®res. Attendu 10 ou 11."
        return info

    # Validation et extraction
    if (len(serial_number_str) == 5 or len(serial_number_str) == 6) and serial_number_str.isdigit():
        info["serial_number"] = serial_number_str
    else:
        info["error"] = "Format du num√©ro de s√©rie invalide."
        return info

    if len(category_year_str) == 3 and category_year_str.isdigit():
        info["category"] = category_year_str[0]
        info["year"] = category_year_str[1:]
    else:
        info["error"] = "Format de la cat√©gorie/ann√©e invalide."
        return info

    if len(wilaya_str) == 2 and wilaya_str.isdigit():
        info["wilaya"] = wilaya_str
    else:
        info["error"] = "Format de la wilaya invalide."
        return info

    # V√©rification des valeurs extraites avec les listes fournies
    if info["category"] in VEHICLE_CATEGORIES and info["wilaya"] in WILAYAS:
        info["is_valid"] = True
    else:
        info["error"] = "Cat√©gorie ou Wilaya non reconnue."

    return info

def get_wilaya_name(wilaya_code: str) -> str:
    """Retourne le nom de la wilaya √† partir de son code."""
    return WILAYAS.get(wilaya_code, "Inconnu")

def get_vehicle_category_name(category_code: str) -> str:
    """Retourne le nom de la cat√©gorie de v√©hicule √† partir de son code."""
    return VEHICLE_CATEGORIES.get(category_code, "Inconnu")

def similarity(a, b):
    """Calcule la similarit√© entre deux cha√Ænes de caract√®res."""
    return SequenceMatcher(None, a, b).ratio()

def deduplicate_plates(detections, similarity_threshold=0.8):
    """
    D√©duplique les plaques similaires et garde la meilleure d√©tection pour chaque plaque unique.
    
    Args:
        detections: Liste des d√©tections
        similarity_threshold: Seuil de similarit√© pour consid√©rer deux plaques comme identiques
    
    Returns:
        Liste des meilleures d√©tections uniques
    """
    if not detections:
        return []
    
    # Grouper les d√©tections similaires
    groups = []
    
    for detection in detections:
        plate_text = detection["text"]
        added_to_group = False
        
        # Chercher un groupe existant avec une plaque similaire
        for group in groups:
            for existing_detection in group:
                if similarity(plate_text, existing_detection["text"]) >= similarity_threshold:
                    group.append(detection)
                    added_to_group = True
                    break
            if added_to_group:
                break
        
        # Si aucun groupe trouv√©, cr√©er un nouveau groupe
        if not added_to_group:
            groups.append([detection])
    
    # Pour chaque groupe, s√©lectionner la meilleure d√©tection
    best_detections = []
    
    for group in groups:
        # Crit√®res de s√©lection (par ordre de priorit√©) :
        # 1. Plaque valide (format correct)
        # 2. Confiance la plus √©lev√©e
        # 3. Longueur de texte appropri√©e (10 ou 11 caract√®res)
        
        valid_detections = [d for d in group if d["parsed_info"]["is_valid"]]
        
        if valid_detections:
            # Prendre la d√©tection valide avec la plus haute confiance
            best_detection = max(valid_detections, key=lambda x: x["confidence"])
        else:
            # Si aucune d√©tection valide, prendre celle avec la plus haute confiance
            # et la longueur la plus proche de 10-11 caract√®res
            def score_detection(d):
                conf_score = d["confidence"]
                length_score = 1.0 if len(d["text"]) in [10, 11] else 0.5
                return conf_score * length_score
            
            best_detection = max(group, key=score_detection)
        
        best_detections.append(best_detection)
    
    return best_detections

# ===============================
# Configuration et initialisation de l'application Streamlit
# ===============================

# Configuration de la page
st.set_page_config(
    page_title="üöó D√©tecteur de Plaques Alg√©riennes",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration des chemins (√† adapter selon votre environnement)
CONFIG = {
    "yolo_model_path": "best.pt",
    "onnx_model_path": "last.onnx",
    "plate_config_path": "algerian_plates.yml",
    "confidence_threshold": 0.5,
    "max_video_size_mb": 100,  # Limite de taille vid√©o en MB
}

# ===============================
# Fonctions de traitement de l'application
# ===============================

@st.cache_resource
def load_models():
    """Charger les mod√®les avec cache pour √©viter le rechargement"""
    try:
        yolo_model = YOLO(CONFIG["yolo_model_path"])
        plate_recognizer = LicensePlateRecognizer(
            onnx_model_path=CONFIG["onnx_model_path"],
            plate_config_path=CONFIG["plate_config_path"],
        )
        logger.info("Mod√®les charg√©s avec succ√®s")
        return yolo_model, plate_recognizer
    except Exception as e:
        logger.error(f"Erreur lors du chargement des mod√®les: {e}")
        st.error(f"‚ùå Erreur lors du chargement des mod√®les: {e}")
        return None, None

# Classe pour le traitement vid√©o en temps r√©el (seulement si webrtc est disponible)
if WEBRTC_AVAILABLE:
    class PlateDetectionProcessor(VideoProcessorBase):
        def __init__(self, yolo_model, plate_recognizer, confidence_threshold):
            self.yolo_model = yolo_model
            self.plate_recognizer = plate_recognizer
            self.confidence_threshold = confidence_threshold
            self.all_detections_in_session = [] # Pour stocker toutes les d√©tections du flux

        def recv(self, frame: VideoFrame) -> VideoFrame:
            img = frame.to_ndarray(format="bgr24")

            processed_img, detections = process_detection(
                img.copy(), self.yolo_model, self.plate_recognizer, self.confidence_threshold
            )
            
            # Sauvegarder les d√©tections pour traitement ult√©rieur (d√©duplication)
            if detections:
                self.all_detections_in_session.extend(detections)
                # Note: save_results est appel√©e apr√®s l'arr√™t du streamer pour la d√©duplication

            return VideoFrame.from_ndarray(processed_img, format="bgr24")

def process_detection(frame, yolo_model, plate_recognizer, confidence_threshold):
    """Traiter la d√©tection sur une image (utilis√© par tous les modes)"""
    detections = []
    
    try:
        results = yolo_model(frame, conf=confidence_threshold)
        
        for result in results:
            if result.boxes is not None:
                for box in result.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                    conf = float(box.conf[0])
                    
                    if conf > confidence_threshold:
                        # Extraire la plaque
                        cropped_plate = frame[y1:y2, x1:x2]
                        
                        # V√©rifier que la plaque n'est pas vide
                        if cropped_plate.size == 0:
                            continue
                            
                        # Pr√©traitement pour l'OCR
                        gray = cv2.cvtColor(cropped_plate, cv2.COLOR_BGR2GRAY)
                        resized = cv2.resize(gray, (128, 64))
                        input_img = np.expand_dims(resized, axis=(0, -1))
                        
                        # Reconnaissance de texte
                        plate_text = plate_recognizer.run(input_img)
                        if isinstance(plate_text, list):
                            plate_text = "".join(plate_text)
                        
                        # Nettoyer le texte et extraire les informations
                        plate_text = str(plate_text).strip()
                        parsed_info = parse_plate_info(plate_text)
                        
                        detections.append({
                            'bbox': (x1, y1, x2, y2),
                            'confidence': conf,
                            'text': plate_text,
                            'parsed_info': parsed_info,
                            'cropped_image': cropped_plate
                        })
                        
                        # Dessiner les annotations
                        # Afficher le texte format√© si valide, sinon le texte brut
                        if parsed_info["is_valid"]:
                            display_text = f"{parsed_info['serial_number']} {parsed_info['category']}{parsed_info['year']} {parsed_info['wilaya']}"
                        else:
                            display_text = plate_text

                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                        
                        # Texte avec arri√®re-plan
                        text = f"{display_text} ({conf:.2f})"
                        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
                        cv2.rectangle(frame, (x1, y1-30), (x1 + text_size[0], y1), (0, 255, 0), -1)
                        cv2.putText(frame, text, (x1, y1 - 10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
    
    except Exception as e:
        logger.error(f"Erreur lors du traitement: {e}")
        st.warning(f"‚ö†Ô∏è Erreur lors du traitement: {e}")
    
    return frame, detections

def save_results(detections, mode="image"):
    """Sauvegarder les r√©sultats dans la session"""
    if 'detection_history' not in st.session_state:
        st.session_state.detection_history = []
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    for detection in detections:
        st.session_state.detection_history.append({
            'timestamp': timestamp,
            'mode': mode,
            'text': detection['text'],
            'confidence': detection['confidence'],
            'parsed_info': detection['parsed_info']
        })

def validate_file_size(uploaded_file, max_size_mb):
    """Valider la taille du fichier upload√©"""
    if uploaded_file is not None:
        file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
        if file_size_mb > max_size_mb:
            st.error(f"‚ùå Le fichier est trop volumineux ({file_size_mb:.1f} MB). Limite: {max_size_mb} MB")
            return False
    return True

# ===============================
# Interface utilisateur principale
# ===============================

def main():
    # Titre principal
    st.title("üöó D√©tection & Reconnaissance de Plaques Alg√©riennes")
    st.markdown("---")
    
    # Sidebar pour les param√®tres
    with st.sidebar:
        st.header("‚öôÔ∏è Param√®tres")
        confidence_threshold = st.slider(
            "Seuil de confiance", 
            min_value=0.1, 
            max_value=1.0, 
            value=CONFIG["confidence_threshold"], 
            step=0.05
        )
        
        st.header("üìä Statistiques")
        if 'detection_history' in st.session_state:
            total_detections = len(st.session_state.detection_history)
            st.metric("D√©tections totales", total_detections)
            
            if total_detections > 0:
                avg_confidence = np.mean([d['confidence'] for d in st.session_state.detection_history])
                st.metric("Confiance moyenne", f"{avg_confidence:.2f}")
        
        # Bouton pour effacer l'historique
        if st.button("üóëÔ∏è Effacer l'historique"):
            st.session_state.detection_history = []
            st.success("Historique effac√©!")
    
    # Chargement des mod√®les
    with st.spinner("üîÑ Chargement des mod√®les..."):
        yolo_model, plate_recognizer = load_models()
    
    if yolo_model is None or plate_recognizer is None:
        st.stop()
    
    st.success("‚úÖ Mod√®les charg√©s avec succ√®s!")
    
    # Choix du mode (conditionnel pour la webcam)
    if WEBRTC_AVAILABLE:
        mode_options = ["üñºÔ∏è Image", "üé• Vid√©o (upload)", "üìπ Temps r√©el (webcam)"]
    else:
        mode_options = ["üñºÔ∏è Image", "üé• Vid√©o (upload)"]
        st.info("‚ÑπÔ∏è Le mode temps r√©el n√©cessite l'installation de streamlit-webrtc")
    
    mode = st.radio(
        "üìã Choisir un mode :", 
        mode_options,
        horizontal=True
    )
    
    # ===============================
    # MODE IMAGE
    # ===============================
    if mode == "üñºÔ∏è Image":
        st.header("üñºÔ∏è Traitement d'image")
        
        uploaded_file = st.file_uploader(
            "Uploader une image", 
            type=["jpg", "jpeg", "png"],
            help="Formats support√©s: JPG, JPEG, PNG"
        )
        
        if uploaded_file:
            # Validation de la taille
            if not validate_file_size(uploaded_file, 10):  # 10 MB pour les images
                return
            
            try:
                file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
                frame = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
                
                if frame is None:
                    st.error("‚ùå Impossible de lire l'image. V√©rifiez le format.")
                    return
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Image originale")
                    st.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), use_column_width=True)
                
                with st.spinner("üîç Traitement en cours..."):
                    processed_frame, detections = process_detection(
                        frame.copy(), yolo_model, plate_recognizer, confidence_threshold
                    )
                
                with col2:
                    st.subheader("R√©sultat de d√©tection")
                    st.image(cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB), use_column_width=True)
                
                # Afficher les r√©sultats
                if detections:
                    st.success(f"‚úÖ {len(detections)} plaque(s) d√©tect√©e(s)!")
                    
                    for i, detection in enumerate(detections):
                        # Utiliser le texte format√© pour l'expander si valide, sinon le texte brut
                        expander_title = f"Plaque {i+1}: "
                        if detection['parsed_info']['is_valid']:
                            expander_title += f"{detection['parsed_info']['serial_number']} {detection['parsed_info']['category']}{detection['parsed_info']['year']} {detection['parsed_info']['wilaya']}"
                        else:
                            expander_title += detection['text']

                        with st.expander(expander_title):
                            col_info, col_crop = st.columns([2, 1])
                            with col_info:
                                st.write(f"**Texte OCR brut:** {detection['text']}")
                                if detection['parsed_info']['is_valid']:
                                    st.write(f"**Num√©ro de s√©rie:** {detection['parsed_info']['serial_number']}")
                                    st.write(f"**Cat√©gorie de v√©hicule:** {get_vehicle_category_name(detection['parsed_info']['category'])} ({detection['parsed_info']['category']})")
                                    st.write(f"**Ann√©e:** 20{detection['parsed_info']['year']}")
                                    st.write(f"**Wilaya:** {get_wilaya_name(detection['parsed_info']['wilaya'])} ({detection['parsed_info']['wilaya']})")
                                else:
                                    st.error(f"‚ùå Format de plaque invalide: {detection['parsed_info']['error']}")
                                st.write(f"**Confiance:** {detection['confidence']:.2f}")
                                st.write(f"**Position:** {detection['bbox']}")
                            with col_crop:
                                st.image(cv2.cvtColor(detection['cropped_image'], cv2.COLOR_BGR2RGB))
                    
                    save_results(detections, "image")
                else:
                    st.warning("‚ö†Ô∏è Aucune plaque d√©tect√©e. Essayez d'ajuster le seuil de confiance.")
                    
            except Exception as e:
                st.error(f"‚ùå Erreur lors du traitement de l'image: {e}")
    
    # ===============================
    # MODE VID√âO
    # ===============================
    elif mode == "üé• Vid√©o (upload)":
        st.header("üé• Traitement de vid√©o")
        
        uploaded_file = st.file_uploader(
            "Uploader une vid√©o", 
            type=["mp4", "avi", "mov"],
            help=f"Formats support√©s: MP4, AVI, MOV (max {CONFIG['max_video_size_mb']} MB)"
        )
        
        if uploaded_file:
            if not validate_file_size(uploaded_file, CONFIG['max_video_size_mb']):
                return
            
            process_video = st.button("üöÄ Commencer le traitement")
            
            if process_video:
                try:
                    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
                    temp_path = tfile.name
                    tfile.write(uploaded_file.read())
                    tfile.close()  # üîë CRUCIAL
                    cap = cv2.VideoCapture(temp_path)

                    if not cap.isOpened():
                        st.error("‚ùå Impossible d'ouvrir la vid√©o")
                        return
                    
                    # Informations sur la vid√©o
                    fps = int(cap.get(cv2.CAP_PROP_FPS))
                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    duration = total_frames / fps if fps > 0 else 0
                    
                    st.info(f"üìπ Vid√©o: {total_frames} frames, {fps} FPS, {duration:.1f}s")
                    
                    stframe = st.empty()
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    frame_count = 0
                    all_detections = []
                    
                    while cap.isOpened():
                        ret, frame = cap.read()
                        if not ret:
                            break
                        
                        frame_count += 1
                        progress = frame_count / total_frames
                        
                        # Traiter seulement quelques frames pour √©viter la surcharge
                        if frame_count % max(1, fps // 2) == 0:  # 2 FPS pour le traitement
                            processed_frame, detections = process_detection(
                                frame.copy(), yolo_model, plate_recognizer, confidence_threshold
                            )
                            all_detections.extend(detections)
                            stframe.image(cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB), channels="RGB")
                        
                        progress_bar.progress(progress)
                        status_text.text(f"Frame {frame_count}/{total_frames}")
                        
                        # Arr√™t si l'utilisateur ferme l'app
                        if not ret:
                            break
                    
                    cap.release()
                    cap = None
                    os.remove(tfile.name)
                    
                    # R√©sum√© final avec d√©duplication intelligente
                    if all_detections:
                        st.success(f"‚úÖ Traitement termin√©! {len(all_detections)} d√©tections au total")
                        
                        # Appliquer la d√©duplication intelligente
                        unique_detections = deduplicate_plates(all_detections)
                        
                        st.info(f"üîç Apr√®s d√©duplication: {len(unique_detections)} plaques uniques d√©tect√©es")
                        
                        # Afficher les r√©sultats d√©dupliqu√©s
                        for i, detection in enumerate(unique_detections, 1):
                            with st.expander(f"üöó V√©hicule {i}"):
                                col_info, col_crop = st.columns([2, 1])
                                with col_info:
                                    # Afficher le texte format√© si valide
                                    if detection['parsed_info']['is_valid']:
                                        formatted_text = f"{detection['parsed_info']['serial_number']} {detection['parsed_info']['category']}{detection['parsed_info']['year']} {detection['parsed_info']['wilaya']}"
                                        st.write(f"**Matricule:** {formatted_text}")
                                        st.write(f"**Num√©ro de s√©rie:** {detection['parsed_info']['serial_number']}")
                                        st.write(f"**Cat√©gorie de v√©hicule:** {get_vehicle_category_name(detection['parsed_info']['category'])} ({detection['parsed_info']['category']})")
                                        st.write(f"**Ann√©e:** 20{detection['parsed_info']['year']}")
                                        st.write(f"**Wilaya:** {get_wilaya_name(detection['parsed_info']['wilaya'])} ({detection['parsed_info']['wilaya']})")
                                    else:
                                        st.write(f"**Matricule (brut):** {detection['text']}")
                                        st.error(f"‚ùå Format invalide: {detection['parsed_info']['error']}")
                                    
                                    st.write(f"**Confiance:** {detection['confidence']:.2f}")
                                    
                                    # Compter les occurrences de cette plaque dans toutes les d√©tections
                                    similar_count = sum(1 for d in all_detections 
                                                      if similarity(d['text'], detection['text']) >= 0.8)
                                    st.write(f"**D√©tections similaires:** {similar_count} fois")
                                    
                                with col_crop:
                                    st.image(cv2.cvtColor(detection['cropped_image'], cv2.COLOR_BGR2RGB))
                        
                        # Sauvegarder seulement les d√©tections uniques
                        save_results(unique_detections, "video")
                        
                    else:
                        st.warning("‚ö†Ô∏è Aucune plaque d√©tect√©e dans la vid√©o")
                        
                except Exception as e:
                    st.error(f"‚ùå Erreur lors du traitement de la vid√©o: {e}")
    
    # ===============================
    # MODE TEMPS R√âEL (seulement si webrtc disponible)
    # ===============================
    elif mode == "üìπ Temps r√©el (webcam)" and WEBRTC_AVAILABLE:
        st.header("üìπ D√©tection en temps r√©el")
        
        # Utilisation de streamlit-webrtc
        webrtc_ctx = webrtc_streamer(
            key="plate_detection",
            video_processor_factory=lambda: PlateDetectionProcessor(yolo_model, plate_recognizer, confidence_threshold),
            rtc_configuration={
                "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
            },
            media_stream_constraints={
                "video": True,
                "audio": False
            },
            async_processing=True,
        )

        if webrtc_ctx.state.playing:
            st.write("üìπ Webcam en cours...")
            st.info("Appuyez sur 'STOP' pour arr√™ter et voir les r√©sultats")
        elif webrtc_ctx.state.stopped:
            # R√©cup√©rer les d√©tections du processeur apr√®s l'arr√™t du flux
            if webrtc_ctx.video_processor and hasattr(webrtc_ctx.video_processor, 'all_detections_in_session'):
                all_detections_from_webcam = webrtc_ctx.video_processor.all_detections_in_session
                if all_detections_from_webcam:
                    st.success(f"‚úÖ Session termin√©e! {len(all_detections_from_webcam)} d√©tections au total")
                    unique_detections = deduplicate_plates(all_detections_from_webcam)
                    st.info(f"üîç Apr√®s d√©duplication: {len(unique_detections)} plaques uniques d√©tect√©es")
                    
                    for i, detection in enumerate(unique_detections, 1):
                        with st.expander(f"üöó V√©hicule {i}"):
                            col_info, col_crop = st.columns([2, 1])
                            with col_info:
                                if detection['parsed_info']['is_valid']:
                                    formatted_text = f"{detection['parsed_info']['serial_number']} {detection['parsed_info']['category']}{detection['parsed_info']['year']} {detection['parsed_info']['wilaya']}"
                                    st.write(f"**Matricule:** {formatted_text}")
                                    st.write(f"**Num√©ro de s√©rie:** {detection['parsed_info']['serial_number']}")
                                    st.write(f"**Cat√©gorie de v√©hicule:** {get_vehicle_category_name(detection['parsed_info']['category'])} ({detection['parsed_info']['category']})")
                                    st.write(f"**Ann√©e:** 20{detection['parsed_info']['year']}")
                                    st.write(f"**Wilaya:** {get_wilaya_name(detection['parsed_info']['wilaya'])} ({detection['parsed_info']['wilaya']})")
                                else:
                                    st.write(f"**Matricule (brut):** {detection['text']}")
                                    st.error(f"‚ùå Format invalide: {detection['parsed_info']['error']}")
                                st.write(f"**Confiance:** {detection['confidence']:.2f}")
                                similar_count = sum(1 for d in all_detections_from_webcam 
                                                  if similarity(d['text'], detection['text']) >= 0.8)
                                st.write(f"**D√©tections similaires:** {similar_count} fois")
                            with col_crop:
                                st.image(cv2.cvtColor(detection['cropped_image'], cv2.COLOR_BGR2RGB))
                    
                    save_results(unique_detections, "webcam")
                else:
                    st.info("‚ÑπÔ∏è Aucune plaque d√©tect√©e via la webcam.")

    # ===============================
    # HISTORIQUE DES D√âTECTIONS
    # ===============================
    if 'detection_history' in st.session_state and st.session_state.detection_history:
        st.markdown("---")
        st.header("üìã Historique des d√©tections")
        
        df = pd.DataFrame(st.session_state.detection_history)
        
        # Filtres
        col1, col2, col3 = st.columns(3)
        with col1:
            mode_filter = st.selectbox("Filtrer par mode:", ["Tous"] + df['mode'].unique().tolist())
        with col2:
            min_conf = st.slider("Confiance minimale:", 0.0, 1.0, 0.0, 0.1)
        
        # Appliquer les filtres
        filtered_df = df.copy()
        if mode_filter != "Tous":
            filtered_df = filtered_df[filtered_df['mode'] == mode_filter]
        filtered_df = filtered_df[filtered_df['confidence'] >= min_conf]
        
        # Extraire les informations de la colonne 'parsed_info'
        if not filtered_df.empty:
            parsed_data = filtered_df['parsed_info'].apply(pd.Series)
            display_df = pd.concat([
                filtered_df[['timestamp', 'mode', 'text', 'confidence']],
                parsed_data[['serial_number', 'category', 'year', 'wilaya']]
            ], axis=1)

            # Renommer les colonnes pour un affichage plus clair
            display_df.rename(columns={
                'serial_number': 'Num√©ro de S√©rie',
                'category': 'Cat√©gorie',
                'year': 'Ann√©e',
                'wilaya': 'Wilaya'
            }, inplace=True)

            # Remplacer les codes par les noms correspondants
            display_df['Cat√©gorie'] = display_df['Cat√©gorie'].apply(get_vehicle_category_name)
            display_df['Wilaya'] = display_df['Wilaya'].apply(get_wilaya_name)
            display_df['Ann√©e'] = display_df['Ann√©e'].apply(lambda y: f"20{y}" if y else None)

            # Afficher le tableau am√©lior√©
            st.dataframe(display_df)
        else:
            st.dataframe(filtered_df)
        
        # T√©l√©charger l'historique
        csv = filtered_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger l'historique (CSV)",
            data=csv,
            file_name="detection_history.csv",
            mime="text/csv",
        )

# ===============================
# M√âTHODES ALTERNATIVES POUR LA WEBCAM
# ===============================

def alternative_webcam_method():
    """M√©thode alternative utilisant OpenCV pour la webcam (sans streamlit-webrtc)"""
    st.header("üìπ D√©tection en temps r√©el (m√©thode alternative)")
    st.warning("‚ö†Ô∏è Cette m√©thode utilise OpenCV directement. Fermez la fen√™tre OpenCV pour revenir √† Streamlit.")
    
    if st.button("üöÄ Lancer la d√©tection webcam"):
        with st.spinner("üîÑ Chargement des mod√®les..."):
            yolo_model, plate_recognizer = load_models()
        
        if yolo_model is None or plate_recognizer is None:
            return
        
        confidence_threshold = st.sidebar.slider(
            "Seuil de confiance", 
            min_value=0.1, 
            max_value=1.0, 
            value=0.5, 
            step=0.05
        )
        
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            st.error("‚ùå Impossible d'acc√©der √† la webcam")
            return
        
        st.info("üìπ Webcam lanc√©e! Appuyez sur 'q' dans la fen√™tre OpenCV pour arr√™ter.")
        all_detections = []
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            processed_frame, detections = process_detection(
                frame.copy(), yolo_model, plate_recognizer, confidence_threshold
            )
            
            if detections:
                all_detections.extend(detections)
            
            cv2.imshow('D√©tection de plaques', processed_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        
        # Traiter les r√©sultats
        if all_detections:
            unique_detections = deduplicate_plates(all_detections)
            st.success(f"‚úÖ Session termin√©e! {len(unique_detections)} plaques uniques d√©tect√©es")
            
            for i, detection in enumerate(unique_detections, 1):
                with st.expander(f"üöó V√©hicule {i}"):
                    col_info, col_crop = st.columns([2, 1])
                    with col_info:
                        if detection['parsed_info']['is_valid']:
                            formatted_text = f"{detection['parsed_info']['serial_number']} {detection['parsed_info']['category']}{detection['parsed_info']['year']} {detection['parsed_info']['wilaya']}"
                            st.write(f"**Matricule:** {formatted_text}")
                            st.write(f"**Num√©ro de s√©rie:** {detection['parsed_info']['serial_number']}")
                            st.write(f"**Cat√©gorie de v√©hicule:** {get_vehicle_category_name(detection['parsed_info']['category'])} ({detection['parsed_info']['category']})")
                            st.write(f"**Ann√©e:** 20{detection['parsed_info']['year']}")
                            st.write(f"**Wilaya:** {get_wilaya_name(detection['parsed_info']['wilaya'])} ({detection['parsed_info']['wilaya']})")
                        else:
                            st.write(f"**Matricule (brut):** {detection['text']}")
                            st.error(f"‚ùå Format invalide: {detection['parsed_info']['error']}")
                        st.write(f"**Confiance:** {detection['confidence']:.2f}")
                    with col_crop:
                        st.image(cv2.cvtColor(detection['cropped_image'], cv2.COLOR_BGR2RGB))
            
            save_results(unique_detections, "webcam_alternative")
        else:
            st.info("‚ÑπÔ∏è Aucune plaque d√©tect√©e.")

# Ajouter la m√©thode alternative si webrtc n'est pas disponible
if not WEBRTC_AVAILABLE:
    st.markdown("---")
    alternative_webcam_method()

if __name__ == "__main__":
    main()
